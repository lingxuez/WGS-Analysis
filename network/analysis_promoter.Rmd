---
title: "Analysis for Promoter"
output:
  pdf_document: default
  html_document: default
---

```{r, echo = F}
rm(list=ls())
load("../results/results_promoter.RData")
cor_vec <- as.numeric(cor_mat)
fdr_cutoff <- 0.0105
```

# Input data (Z-values)

We start with a histogram of the test statistics for annotations. 
Here, we take values in the column named "Perm\_p". In the following section, we show what the other rows look like. We apply the following rule:
if "Adjusted\_relative\_risk" is less than 1 and "Perm\_p" is less than 0.5, than
we replace "Perm\_p" with 1-"Perm\_p".  
Below, we show the distribution of the z-values for the annotations that have more
than a total count of 20. 

```{r, echo = F}
tmp <- vec1[which(!flag_vec)]
min_val <- floor(min(tmp, na.rm = T)/1)-.1
max_val <- ceiling(max(tmp, na.rm = T)/1)+.1
hist(tmp, col = "gray", breaks = seq(min_val, max_val, by = 0.2),
     main = "Histogram of (Raw) z-values", xlab = "z-values")
```


# Test statistics

As hinted in the previous subsection, we remove the annotations within a cluster that
1) does not have a value recorded for "Perm\_p" in the original dataset, or
<!-- 2) removed annotations with more than 3 "Con_count_adj". -->
<!-- There are 18 clusters removed (25\%). -->
2) does not have more than a total count of 20. However, in doing so,
23 of the 70 clusters (32\%) have no annotations in them. This means there are 47 clusters for the remainder of our analysis.

```{r}
max(clustering)
size_threshold
length(which(size_vec < size_threshold))
length(which(size_vec < size_threshold))/length(size_vec)
```



For cluster $i$, let $n_i$ be the number of annotations in the $i$th cluster.
This corresponds with a square submatrix $\Sigma_i \in \mathbb{R}^{n_i \times n_i}$
within $\Sigma$ as well as a subvector $Z_i \in \mathbb{R}^{n_i}$ within $Z$.
To compute the test statistic,
we compute the leading eigenvector $u_i \in \mathbb{R}^{n_i}$, and have the
cluster z-values be defiend as
\[
s_i \cdot \sqrt{\frac{(u_i^TZ_i)^2}{u_i^T\Sigma_i u_i}},
\]
where $s_i = 1$ if there are more positive entries in $u_i^TZ_i$ than negative
entries, and $s_i = -1$ if there are more negative entries in $u_i^TZ_i$ than
positive entries.

We use sparse PCA to model the $u_i$'s. Below, we plot the difference between the 
test statistics when we use sparse PCA verses PCA. We see that with sparse PCA, the
test statistic for certain cluster becomes higher.

```{r, echo = F}
plot(zval_supernode, testvec_res2$vec, pch = 16, xlab = "With sparse PCA", ylab = "With PCA",
     asp = T)
lines(c(-500, 500), c(-500, 500), col = "red", lwd = 2, lty = 2)
```

To invesitgate the sparsity induced by sparse PCA, we plot a scatterplot of the sparsity of 
a cluster (the number of annotations selected to be used in the calculation of a cluster's test statistic)
verses the number of annotations in that cluster.
We see that most small clusters retained all their annotations, while the larger annotations
only have roughly half the annotations selected.

```{r, echo = F}
plot(y = testvec_res$sparsity, x = sapply(testvec_res$index, length)/testvec_res$sparsity,
     pch = 16, xlab = "Number of annotations in cluster", ylab = "Sparsity of cluster")
```


Below is a histogram of the cluster z-values (not including the clusters with
no annotations).

```{r, echo = F}
tmp <- zval_supernode[zval_supernode != 0]
min_val <- floor(min(tmp)/1)-.1
max_val <- ceiling(max(tmp)/1)+.1
hist(tmp, col = "gray", breaks = seq(min_val, max_val, by = 0.2),
     main = "", xlab = "Cluster z-values")
```

Overall, we can get a sense of the relationship between the clusters' z-values and
the individual annotations' z-values by plotting the clusters' z-values
against the average z-values of the individual annotations within each cluster.

```{r, echo = F}
zz <- rep(0, length(cluster_idx))
for(i in 1:length(cluster_idx)){
  idx2 <- which(clustering == cluster_idx[i])
  zval_tmp <- vec1[idx2]
  flag_tmp <- flag_vec[idx2]
  idx2 <- intersect(which(!is.na(zval_tmp)), which(!flag_tmp))
  zz[i] <- mean(zval_tmp[idx2])
}
plot(zz, zval_supernode, pch = 16, xlab = "Average z-value of annotations in cluster", ylab = "Cluster z-value")
```

# Input data (Correlation values)

Recall that 23 of the clusters have too few annotations in them.
That means our subsequent analysis only deals with the remaining 47 clusters. 

Next, we plot the empirical CDF of the average (mean) correlation among all
${47 \choose 2}$ off-diagonal submatrices. These values will dictate the 
supernode graph. We see that with a correlation threshold of 0.12, only
roughly 8\% of the possible edges are in our correlation graph.

```{r, echo = F}
plot(y = seq(0, 1, length.out = length(cor_vec)), x = sort(cor_vec), pch = 16, main = "Empirical CDF of 
     average value in off-diagonal blocks", xlab = "Correlation value",
     ylab = "Quantile")
lines(y = c(-50, 1e10), x = rep(cor_threshold, 2), col = "red", lwd = 2, lty = 2)

tmp <- length(which(cor_vec <= cor_threshold))/length(cor_vec)
lines(y = rep(tmp, 2), x = c(-10, 10), col = "red", lwd = 2, lty = 2)
```

We will remove all the clusters that have too few annotations in them.
In doing so, we only have 47
nodes remaining.

We estimate the supernode graph via a hard threshold at 0.12 Roughly 8\% of all
possible edges are added in this way.

```{r}
cor_threshold
length(which(cor_vec > cor_threshold))/length(cor_vec)
```

# DAWN results

Before running DAWN, we can shade each node by its corresponding test statistic.

```{r, echo = F}
maxz <- max(zval_supernode)
minz <- min(zval_supernode)

node_size <- sapply(cluster_idx, function(x){
  length(which(clustering == x))
})
node_size <- (node_size - min(node_size))/max(node_size)
node_size <- 2*(node_size+1)^2

node_col <- sapply(zval_supernode, function(x){
  tmp <- (maxz-x)/(maxz-minz)
  tmp <- 1/(1+exp(-10*(tmp - 0.2)))
  rgb(1, tmp, tmp)
})
set.seed(10)
igraph::plot.igraph(g, vertex.size = node_size, vertex.label = NA,
                    vertex.color = node_col, main = "Pre-DAWN")
```

After running DAWN, we can shade each node by whether or not DAWN has classified
the gene as "Type 1" (i.e., comes from shifted mean).
Recall that in DAWN, the HMRF assumes that the $Z$ values are distributed
\[
Z_i \sim P(I_i = 0)N(0, \sigma^2) + P(I_i = 1)N(\mu, \sigma^2).
\]
Using a Gibbs sampler, we can estimate the posterior probability a node is "Type 1".
This posterior probability leads to a Bayesian FDR. We show all nodes that had a Bayesian
FDR of less than 0.01 in red below.

```{r, echo = F}
node_col2 <- rep("white", length(zval_supernode))
node_col2[which(fdr$FDR <= fdr_cutoff)] <- "red"
set.seed(10)
igraph::plot.igraph(g, vertex.size = node_size, vertex.label = NA,
                    vertex.color = node_col2, main = "Post-DAWN, Coloring by labeling")
```

### Inspecting DAWN results

The DAWN $c$ value (informing how important the graph is to fit the test statistics)
is 0.2.

```{r}
res$b
res$c
res$mu1
res$mu2
res$sigma1
res$sigma2
```

We plot, for each node, the value of the test-statistic prior to using DAWN
against the number of neighboring "Type I" nodes. We see the desired effect: clusters are labeled as 
"Type I" if the original test statistic was very large or if they have many "Type I" neighbors.

```{r, echo = F}
zmax <- max(zval_supernode)
zmin <- min(zval_supernode)

dis_mat <- igraph::distances(g)
idx2 <- which(fdr$FDR <= fdr_cutoff)
neighboring_vec <- sapply(1:nrow(dis_mat), function(x){
  tmp_idx <- idx2[idx2 != x]
  length(which(dis_mat[x,tmp_idx] <= 1))
})

node_col4 <- rep("black", nrow(dis_mat))
node_col4[idx2] <- "red"
plot(NA, xlim = c(zmin, zmax), ylim = c(0, max(neighboring_vec)), main = 
       "Number of Type I neighbors vs. Pre-DAWN test statistic", xlab = 
       "Pre-DAWN test statistic", ylab = "Number of Type I neighbors")
for(i in seq(0, max(neighboring_vec), by = 2)){
  lines(x = c(-1e4, 1e4), y = rep(i, 2), lwd = 2, lty = 2, col = "gray")
}
points(y = neighboring_vec, x = zval_supernode, col = node_col4, pch = 16)
```

### Trying other graphs

We try the graphs for correlation threshold for three other correlation thresholds. 
We plot the graphs with an Bayesian FDR threshold of 0.01 in the same format
as above.

```{r, echo = F, fig.height = 4}
par(mfrow = c(1, length(threshold_vec)), mar = c(0,0,2,0))

for(i in 1:length(threshold_vec)){
  node_col2_tmp <- rep("white", length(zval_supernode))
  node_col2_tmp[which(fdr_list[[i]]$FDR <= fdr_cutoff)] <- "red"
  
  set.seed(10)
  igraph::plot.igraph(g_list[[i]], vertex.size = node_size, vertex.label = NA,
                    vertex.color = node_col2_tmp, main = paste0("For correlation ",
                                                                threshold_vec[i]))
}

```

The graph for number of neighbors vs. test statistic (similar to above) for all three
graphs are show below.

```{r, echo = F, fig.height = 3}
par(mfrow = c(1, length(threshold_vec)), mar = c(5, 4, 4, 0.1))

zmax <- max(zval_supernode)
zmin <- min(zval_supernode)

for(i in 1:length(threshold_vec)){
  dis_mat <- igraph::distances(g_list[[i]])
  idx2 <- which(fdr_list[[i]]$FDR <= fdr_cutoff)
  neighboring_vec <- sapply(1:nrow(dis_mat), function(x){
    tmp_idx <- idx2[idx2 != x]
    length(which(dis_mat[x,tmp_idx] <= 1))
  })
  
  node_col4 <- rep("black", nrow(dis_mat))
  node_col4[idx2] <- "red"
  plot(NA, xlim = c(zmin, zmax), ylim = c(0, max(neighboring_vec)), main = 
         paste0("For correlation ", threshold_vec[i]), xlab = 
         "Pre-DAWN test statistic", ylab = "Number of Type I neighbors")
  for(i in seq(0, max(neighboring_vec), by = 2)){
    lines(x = c(-1e4, 1e4), y = rep(i, 2), lwd = 2, lty = 2, col = "gray")
  }
  points(y = neighboring_vec, x = zval_supernode, col = node_col4, pch = 16)
}
```

# Post-analysis with adjusted relative risk

Here, we do all the relevant analyses for adjusted relative risk.

### Annotation's adjusted relative risk

We investigate how many of the annotations have an adjusted relative risk
less than 1.

```{r}
tmp <- dat2$Adjusted_relative_risk[idx]
length(tmp)
length(which(tmp <= 1))/length(tmp)
length(which(tmp == 0))/length(tmp)
length(which(is.infinite(tmp)))/length(tmp)
```


Below, we plot a histogram of the log adjusted relative risks, omitting
those that are infinite (positive or negative).

```{r, echo = F}
tmp <- risk1[!is.infinite(risk1)]
min_val <- floor(min(tmp, na.rm = T)/1)-.1
max_val <- ceiling(max(tmp, na.rm = T)/1)+.1
hist(tmp, col = "gray", breaks = seq(min_val, max_val, by = 0.2),
     main = "Histogram of log adjusted relative risk", xlab = "z-values")
```

### Clusters' adjusted relative risk

We take the log of adjusted relative risk, apply our same aggregation strategy,
and then take the exponent of the resulting value.

Prior to taking the last exponent, we plot the mean logged adjusted relative risk
to our aggregated statistic.

```{r, echo = F}
zz <- rep(0, length(cluster_idx))
tmp <- dat2$Adjusted_relative_risk[idx]
tmp <- log(tmp)

for(i in 1:length(cluster_idx)){
  idx2 <- which(clustering == cluster_idx[i])
  zval_tmp <- tmp[idx2]
  flag_tmp <- flag_vec2[idx2]
  idx2 <- intersect(which(!is.na(zval_tmp)), which(!flag_tmp))
  zz[i] <- mean(zval_tmp[idx2])
}
plot(zz, log(risk_supernode), pch = 16, xlab = "Average logged adjusted relative risk", ylab = "Logged cluster adjusted relative risk")
```

Here is the histogram of the clusters' logged adjusted relative risk.

```{r, echo = F}
tmp <- log(risk_supernode)
tmp <- tmp[which(!is.infinite(tmp))]
min_val <- floor(min(tmp)/1)-.1
max_val <- ceiling(max(tmp)/1)+.1
hist(tmp, col = "gray", breaks = seq(min_val, max_val, by = 0.1),
     main = "", xlab = "Cluster logged adjusted relative risk")
```

### Graph with clusters' adjusted relative risk

Lastly, we plot the adjusted relative risk with respect to the graph.

```{r, echo = F}
rtmp <- log(risk_supernode)
tmax <- max(rtmp)
tmin <- min(rtmp)

node_col_risk <- sapply(rtmp, function(x){
  tmp <- (tmax-x)/(tmax-tmin)
  tmp <- 1/(1+exp(-5*(tmp - 0.2)))
  rgb(1, tmp, tmp)
})

set.seed(10)
igraph::plot.igraph(g, vertex.size = node_size, vertex.label = NA,
                    vertex.color = node_col_risk, main = "")
```

### Cluster adjusted relative risk vs. test statistic

We plot the negative log (base 10) of the one-sided p-value of each cluster (based on
whether or not the adjusted relative risk of the cluster is larger or smaller
than 1) against the adjusted relative risk of the cluster. 

```{r, echo = F}
node_col5 <- node_col2
node_col2[node_col2 == "white"] <- "black"
zz <- rep(NA, length(zval_supernode))
#zz[which(risk_supernode >= 1)] <- 1-pnorm(zval_supernode[which(risk_supernode >= 1)])
#zz[which(risk_supernode < 1)] <- pnorm(zval_supernode[which(risk_supernode < 1)])

zz[which(risk_supernode >= 1)] <- 1-pchisq(zval_supernode[which(risk_supernode >= 1)]^2, df = 1)
zz[which(risk_supernode < 1)] <- pchisq(zval_supernode[which(risk_supernode >= 1)]^2, df = 1)

plot(risk_supernode, -log(zz, 10), pch = 16, col = node_col2,
     xlab = "Cluster relative risk", ylab = "-log cluster p-value base 10")
```

